{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Converting songs to matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/180 [00:01<04:32,  1.53s/it]\u001b[A\n",
      "  1%|          | 2/180 [00:02<04:18,  1.45s/it]\u001b[A\n",
      "  2%|▏         | 3/180 [00:03<02:57,  1.00s/it]\u001b[A\n",
      "  2%|▏         | 4/180 [00:03<02:26,  1.20it/s]\u001b[A\n",
      "  3%|▎         | 6/180 [00:03<01:40,  1.73it/s]\u001b[A\n",
      "  4%|▍         | 7/180 [00:03<01:29,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 8/180 [00:03<01:19,  2.18it/s]\u001b[A\n",
      "  6%|▌         | 10/180 [00:04<01:09,  2.46it/s]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dam/anaconda3/envs/py36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/dam/anaconda3/envs/py36/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/dam/anaconda3/envs/py36/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      " 98%|█████████▊| 176/180 [01:47<00:02,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Converted 176 songs to matrix\n",
      "\n",
      "\n",
      "\n",
      "(300, 156)\n",
      "Processing song, 0\n",
      "Processing song, 1\n",
      "Processing song, 2\n",
      "Processing song, 3\n",
      "Processing song, 4\n",
      "Processing song, 5\n",
      "Processing song, 6\n",
      "Processing song, 7\n",
      "Processing song, 8\n",
      "Processing song, 9\n",
      "Processing song, 10\n",
      "Processing song, 11\n",
      "Processing song, 12\n",
      "Processing song, 13\n",
      "Processing song, 14\n",
      "Processing song, 15\n",
      "Processing song, 16\n",
      "Processing song, 17\n",
      "Processing song, 18\n",
      "Processing song, 19\n",
      "Processing song, 20\n",
      "Processing song, 21\n",
      "Processing song, 22\n",
      "Processing song, 23\n",
      "Processing song, 24\n",
      "Processing song, 25\n",
      "Processing song, 26\n",
      "Processing song, 27\n",
      "Processing song, 28\n",
      "Processing song, 29\n",
      "Processing song, 30\n",
      "Processing song, 31\n",
      "Processing song, 32\n",
      "Processing song, 33\n",
      "Processing song, 34\n",
      "Processing song, 35\n",
      "Processing song, 36\n",
      "Processing song, 37\n",
      "Processing song, 38\n",
      "Processing song, 39\n",
      "Processing song, 40\n",
      "Processing song, 41\n",
      "Processing song, 42\n",
      "Processing song, 43\n",
      "Processing song, 44\n",
      "Processing song, 45\n",
      "Processing song, 46\n",
      "Processing song, 47\n",
      "Processing song, 48\n",
      "Processing song, 49\n",
      "Processing song, 50\n",
      "Processing song, 51\n",
      "Processing song, 52\n",
      "Processing song, 53\n",
      "Processing song, 54\n",
      "Processing song, 55\n",
      "Processing song, 56\n",
      "Processing song, 57\n",
      "Processing song, 58\n",
      "Processing song, 59\n",
      "Processing song, 60\n",
      "Processing song, 61\n",
      "Processing song, 62\n",
      "Processing song, 63\n",
      "Processing song, 64\n",
      "Processing song, 65\n",
      "Processing song, 66\n",
      "Processing song, 67\n",
      "Processing song, 68\n",
      "Processing song, 69\n",
      "Processing song, 70\n",
      "Processing song, 71\n",
      "Processing song, 72\n",
      "Processing song, 73\n",
      "Processing song, 74\n",
      "Processing song, 75\n",
      "Processing song, 76\n",
      "Processing song, 77\n",
      "Processing song, 78\n",
      "Processing song, 79\n",
      "Processing song, 80\n",
      "Processing song, 81\n",
      "Processing song, 82\n",
      "Processing song, 83\n",
      "Processing song, 84\n",
      "Processing song, 85\n",
      "Processing song, 86\n",
      "Processing song, 87\n",
      "Processing song, 88\n",
      "Processing song, 89\n",
      "Processing song, 90\n",
      "Processing song, 91\n",
      "Processing song, 92\n",
      "Processing song, 93\n",
      "Processing song, 94\n",
      "Processing song, 95\n",
      "Processing song, 96\n",
      "Processing song, 97\n",
      "Processing song, 98\n",
      "Processing song, 99\n",
      "Processing song, 100\n",
      "Processing song, 101\n",
      "Processing song, 102\n",
      "Processing song, 103\n",
      "Processing song, 104\n",
      "Processing song, 105\n",
      "Processing song, 106\n",
      "Processing song, 107\n",
      "Processing song, 108\n",
      "Processing song, 109\n",
      "Processing song, 110\n",
      "Processing song, 111\n",
      "Processing song, 112\n",
      "Processing song, 113\n",
      "Processing song, 114\n",
      "Processing song, 115\n",
      "Processing song, 116\n",
      "Processing song, 117\n",
      "Processing song, 118\n",
      "Processing song, 119\n",
      "Processing song, 120\n",
      "Processing song, 121\n",
      "Processing song, 122\n",
      "Processing song, 123\n",
      "Processing song, 124\n",
      "Processing song, 125\n",
      "Processing song, 126\n",
      "Processing song, 127\n",
      "Processing song, 128\n",
      "Processing song, 129\n",
      "Processing song, 130\n",
      "Processing song, 131\n",
      "Processing song, 132\n",
      "Processing song, 133\n",
      "Processing song, 134\n",
      "Processing song, 135\n",
      "Processing song, 136\n",
      "Processing song, 137\n",
      "Processing song, 138\n",
      "Processing song, 139\n",
      "Processing song, 140\n",
      "Processing song, 141\n",
      "Processing song, 142\n",
      "Processing song, 143\n",
      "Processing song, 144\n",
      "Processing song, 145\n",
      "Processing song, 146\n",
      "Processing song, 147\n",
      "Processing song, 148\n",
      "Processing song, 149\n",
      "Processing song, 150\n",
      "Processing song, 151\n",
      "Processing song, 152\n",
      "Processing song, 153\n",
      "Processing song, 154\n",
      "Processing song, 155\n",
      "Processing song, 156\n",
      "Processing song, 157\n",
      "Processing song, 158\n",
      "Processing song, 159\n",
      "Processing song, 160\n",
      "Processing song, 161\n",
      "Processing song, 162\n",
      "Processing song, 163\n",
      "Processing song, 164\n",
      "Processing song, 165\n",
      "Processing song, 166\n",
      "Processing song, 167\n",
      "Processing song, 168\n",
      "Processing song, 169\n",
      "Processing song, 170\n",
      "Processing song, 171\n",
      "Processing song, 172\n",
      "Processing song, 173\n",
      "Processing song, 174\n",
      "Processing song, 175\n",
      "Processing song, 176\n",
      "Processing song, 177\n",
      "Processing song, 178\n",
      "Processing song, 179\n",
      "Processing song, 180\n",
      "Processing song, 181\n",
      "Processing song, 182\n",
      "Processing song, 183\n",
      "Processing song, 184\n",
      "Processing song, 185\n",
      "Processing song, 186\n",
      "Processing song, 187\n",
      "Processing song, 188\n",
      "Processing song, 189\n",
      "Processing song, 190\n",
      "Processing song, 191\n",
      "Processing song, 192\n",
      "Processing song, 193\n",
      "Processing song, 194\n",
      "Processing song, 195\n",
      "Processing song, 196\n",
      "Processing song, 197\n",
      "Processing song, 198\n",
      "Processing song, 199\n",
      "Processing song, 200\n",
      "Processing song, 201\n",
      "Processing song, 202\n",
      "Processing song, 203\n",
      "Processing song, 204\n",
      "Processing song, 205\n",
      "Processing song, 206\n",
      "Processing song, 207\n",
      "Processing song, 208\n",
      "Processing song, 209\n",
      "Processing song, 210\n",
      "Processing song, 211\n",
      "Processing song, 212\n",
      "Processing song, 213\n",
      "Processing song, 214\n",
      "Processing song, 215\n",
      "Processing song, 216\n",
      "Processing song, 217\n",
      "Processing song, 218\n",
      "Processing song, 219\n",
      "Processing song, 220\n",
      "Processing song, 221\n",
      "Processing song, 222\n",
      "Processing song, 223\n",
      "Processing song, 224\n",
      "Processing song, 225\n",
      "Processing song, 226\n",
      "Processing song, 227\n",
      "Processing song, 228\n",
      "Processing song, 229\n",
      "Processing song, 230\n",
      "Processing song, 231\n",
      "Processing song, 232\n",
      "Processing song, 233\n",
      "Processing song, 234\n",
      "Processing song, 235\n",
      "Processing song, 236\n",
      "Processing song, 237\n",
      "Processing song, 238\n",
      "Processing song, 239\n",
      "Processing song, 240\n",
      "Processing song, 241\n",
      "Processing song, 242\n",
      "Processing song, 243\n",
      "Processing song, 244\n",
      "Processing song, 245\n",
      "Processing song, 246\n",
      "Processing song, 247\n",
      "Processing song, 248\n",
      "Processing song, 249\n",
      "Processing song, 250\n",
      "Processing song, 251\n",
      "Processing song, 252\n",
      "Processing song, 253\n",
      "Processing song, 254\n",
      "Processing song, 255\n",
      "Processing song, 256\n",
      "Processing song, 257\n",
      "Processing song, 258\n",
      "Processing song, 259\n",
      "[*] Embedding Songs\n",
      "(300, 333)\n",
      "(300, 156)\n",
      "Number of samples: 260\n",
      "Number of unique input tokens: 333\n",
      "Number of unique output tokens: 333\n",
      "Max sequence length for inputs: 300\n",
      "Max sequence length for outputs: 300\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-954c1f51de4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                                                                         \u001b[0mnum_encoder_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                                                                         \u001b[0mmax_decoder_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                                                         num_decoder_tokens)\n\u001b[0m",
      "\u001b[0;32m~/MachineLearning/seq2seq4music_generation/utils.py\u001b[0m in \u001b[0;36mget_input_data\u001b[0;34m(input_songs, target_songs, max_encoder_seq_length, num_encoder_tokens, max_decoder_seq_length, num_decoder_tokens)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \t    encoder_input_data[i] = np.concatenate((input_song, \n\u001b[0;32m--> 136\u001b[0;31m \t            np.zeros((max_encoder_seq_length-input_song.shape[0], num_encoder_tokens))))\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import midi_manipulation\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from distutils.version import LooseVersion\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_songs, target_songs = get_song_matrixes('./blues', 176, 300)\n",
    "\n",
    "input_songs = np.array(input_songs)\n",
    "target_songs = np.array(target_songs)\n",
    "\n",
    "\n",
    "tokens = get_tokens(input_songs)\n",
    "num_encoder_tokens = np.array(tokens).shape[0]\n",
    "num_decoder_tokens = np.array(tokens).shape[0]\n",
    "\n",
    "\n",
    "print('[*] Embedding Songs')\n",
    "embeded_input_songs = get_embeded_songs(input_songs, tokens, num_encoder_tokens)\n",
    "embeded_target_songs = get_embeded_songs(input_songs, tokens, num_encoder_tokens)\n",
    "\n",
    "print(np.array(embeded_input_songs[0]).shape)\n",
    "\n",
    "\n",
    "print(np.array(embed_song_to_song(embeded_input_songs[0], tokens)).shape)\n",
    "\n",
    "# Finding the longest song in the dataset\n",
    "max_encoder_seq_length = max([len(song) for song in embeded_input_songs])\n",
    "max_decoder_seq_length = max([len(song) for song in embeded_target_songs])\n",
    "\n",
    "\n",
    "print('Number of samples:', len(input_songs))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)# Get input data in shape (num_sample, max_seq_length, num_tokens)\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = get_input_data(\n",
    "                                                                        np.array(embeded_input_songs), \n",
    "                                                                        np.array(embeded_target_songs),\n",
    "                                                                        max_encoder_seq_length, \n",
    "                                                                        num_encoder_tokens, \n",
    "                                                                        max_decoder_seq_length, \n",
    "                                                                        num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c02881bd45b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                         \u001b[0mnum_encoder_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                         \u001b[0mmax_decoder_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                         num_decoder_tokens)\n\u001b[0m",
      "\u001b[0;32m~/MachineLearning/seq2seq4music_generation/utils.py\u001b[0m in \u001b[0;36mget_input_data\u001b[0;34m(input_songs, target_songs, max_encoder_seq_length, num_encoder_tokens, max_decoder_seq_length, num_decoder_tokens)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \t    encoder_input_data[i] = np.concatenate((input_song, \n\u001b[0;32m--> 136\u001b[0;31m \t            np.zeros((max_encoder_seq_length-input_song.shape[0], num_encoder_tokens))))\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Get input data in shape (num_sample, max_seq_length, num_tokens)\n",
    "encoder_input_data, decoder_input_data, decoder_target_data = get_input_data(\n",
    "                                                                        embeded_input_songs, \n",
    "                                                                        embeded_target_songs,\n",
    "                                                                        max_encoder_seq_length, \n",
    "                                                                        num_encoder_tokens, \n",
    "                                                                        max_decoder_seq_length, \n",
    "                                                                        num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 333)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 333)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 32), (None,  46848       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 32), ( 46848       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 333)    10989       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 104,685\n",
      "Trainable params: 104,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size  =   16      # Batch size for training.\n",
    "epochs      =   15     # Number of epochs to train for.\n",
    "latent_dim  =   32     # Latent dimensionality of the encoding space.\n",
    "#num_samples =   10000   # Number of samples to train on.\n",
    "\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "print()\n",
    "print(model.summary())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Starting Training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'encoder_input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-542b45298c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[*] Starting Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n\u001b[0m\u001b[1;32m      9\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "with tf.get_default_graph().as_default():\n",
    "    print('[*] Starting Training')\n",
    "    if training:\n",
    "        model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1)\n",
    "    else:\n",
    "        model.load_weights('s2s.h5')\n",
    "    print('[*] Ready to be used \\n\\n')\n",
    "# Save model\n",
    "model.save('s2s.h5')\n",
    "\n",
    "\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 0] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    song_matrix = np.zeros(\n",
    "                        (max_decoder_seq_length, \n",
    "                        num_decoder_tokens),\n",
    "                        dtype='float32')\n",
    "    i = 0\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        idx = np.argmax(output_tokens[-1,-1,:])\n",
    "        #print(output_tokens[-1,-1,:])\n",
    "        song_matrix[i, idx] = 1\n",
    "        target_seq[0, 0, idx] = 1.\n",
    "        \n",
    "        \n",
    "        for rep in range(2):\n",
    "            output_tokens[-1,-1,idx] = 0\n",
    "            idx = np.argmax(output_tokens[-1,-1,:])\n",
    "            #print(output_tokens[-1,-1,:])\n",
    "            song_matrix[i, idx] = 1\n",
    "            target_seq[0, 0, idx] = 1.\n",
    "        \n",
    "        \n",
    "        #print(np.array(h).shape)\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (i+2 > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        \n",
    "        \n",
    "\n",
    "        if i%250 == 0:\n",
    "            print('[iter:{}] [max_decoder_seq_length: {}]'.format(i, max_decoder_seq_length))\n",
    "        i+=1\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return song_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Encoding-Decoding\n",
      "(10, 50, 156)\n",
      "[iter:0] [max_decoder_seq_length: 50]\n",
      "-\n",
      "3530.0\n",
      "150.0\n",
      "(50, 156)\n"
     ]
    }
   ],
   "source": [
    "# Take one sequence (part of the training test)\n",
    "# for trying out decoding.\n",
    "print('[*] Encoding-Decoding')\n",
    "input_seq = encoder_input_data[0:10]\n",
    "print(input_seq.shape)\n",
    "decoded_song = decode_sequence(input_seq)\n",
    "#decoded_song2 = decode_sequence(encoder_input_data[1:6])\n",
    "#decoded_song3 = decode_sequence(encoder_input_data[2:7])\n",
    "#decoded_song4 = decode_sequence(encoder_input_data[3:8])\n",
    "\n",
    "#decoded_song = np.concatenate((decoded_song1,decoded_song2,decoded_song3,decoded_song4), axis = 0)\n",
    "print('-')\n",
    "print(np.sum(input_seq))\n",
    "print(np.sum(decoded_song))\n",
    "\n",
    "\n",
    "\n",
    "# Converting Song to midi from matrix\n",
    "print(np.array(decoded_song).shape)\n",
    "midi_manipulation.noteStateMatrixToMidi(decoded_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midi_manipulation.noteStateMatrixToMidi(decoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(encoder_input_data[0], decoded_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 500, 156)\n",
      "\n",
      "Encoder input data shape: (2, 500, 156)\n",
      "\n",
      "[*] Encoding-Decoding\n",
      "[iter:0] [max_decoder_seq_length: 500]\n",
      "[iter:250] [max_decoder_seq_length: 500]\n",
      "[*] Converting and saving song\n"
     ]
    }
   ],
   "source": [
    "encoded_data = get_encoded_input_data('./blues/BB_King_-_Sweet_Sixteen._mid_', \n",
    "                                max_encoder_seq_length, num_encoder_tokens)                                                                  \n",
    "\n",
    "\n",
    "# Take one sequence (part of the training test)\n",
    "# for trying out decoding.\n",
    "print('[*] Encoding-Decoding')\n",
    "input_seq = encoded_data[0:-1]\n",
    "decoded_song = decode_sequence(input_seq)\n",
    "\n",
    "\n",
    "\n",
    "# Converting Song to midi from matrix\n",
    "print('[*] Converting and saving song')\n",
    "midi_manipulation.noteStateMatrixToMidi(decoded_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
